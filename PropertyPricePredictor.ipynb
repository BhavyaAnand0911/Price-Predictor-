{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first subset is known as the training data - it’s a portion of our actual dataset that is fed into the machine learning model to discover and learn patterns. In this way, it trains our model. \n",
    "\n",
    "# Once your machine learning model is built (with your training data), you need unseen data to test your model. This data is called testing data, and you can use it to evaluate the performance and progress of your algorithms’ training and adjust or optimize it for improved results. \n",
    "# Testing data has two main criteria. It should:\n",
    "# -Represent the actual dataset \n",
    "# -Be large enough to generate meaningful predictions\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# Pandas is an open-source Python package used for data analysis and manipulation tasks. It is built on top of Numpy, which provides support for multi-dimensional arrays.\n",
    "\n",
    "housing=pd.read_csv(\"./data.csv\")\n",
    "# housing.head() # this will display the first 5 rows of the data in table format\n",
    "# housing.info() # this will give the information about the data such as total number of entries\n",
    "\n",
    "# housing['CHAS'].value_counts() # will give the count of all the possible values of the given feature\n",
    "\n",
    "housing.describe() # will give the details of eah feature such as std, mean, min, count, max, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "housing.hist(bins=50,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for learning how the function works internally\n",
    "# import numpy as np\n",
    "\n",
    "# def split_train_test(data,test_ratio):\n",
    "#     np.random.seed(42) #\n",
    "\n",
    "#     shuffled=np.random.permutation(len(data))\n",
    "#     test_set_size=int(len(data)* test_ratio)\n",
    "#     test_indices=shuffled[:test_set_size]\n",
    "#     train_indices=shuffled[test_set_size:]\n",
    "#     return data.iloc[test_indices], data.iloc[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set,train_set=split_train_test(housing,0.2)\n",
    "\n",
    "# print(f\"Rows in training set: {len(train_set)}\\n Rows in test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "train_set,test_set=train_test_split(housing,test_size=0.2,random_state=42)\n",
    "\n",
    "print(f\"Rows in training set: {len(train_set)}\\n Rows in test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index,test_index in split.split(housing,housing['CHAS']):\n",
    "    strat_train_set=housing.loc[train_index]\n",
    "    strat_test_set=housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=strat_train_set.copy() # made housing the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=housing.corr()\n",
    "corr_matrix['MEDV'].sort_values(ascending=False) # calculating the correlation of money wrt all other features\n",
    "\n",
    "# pearson correlation coeff 1 means strong positive correlation \n",
    "# when this value increases the price of the property will increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes=['MEDV','RM','ZN','LSTAT']\n",
    "\n",
    "scatter_matrix(housing[attributes],figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind='scatter', x='RM', y='MEDV', alpha=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out attribute combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['TAXRM']=housing['TAX']/housing['RM']\n",
    "# housing['TAXRM']\n",
    "\n",
    "corr_matrix=housing.corr()\n",
    "corr_matrix['MEDV'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind='scatter', x='TAXRM', y='MEDV', alpha=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 ways to handle missing attributes\n",
    "1. Get rid of the missing data points # newHousing = housing.dropna(subset[\"RM\"])\n",
    "2. Get rid of the whole attribute # housing.drop(\"RM\",axis=1).shape\n",
    "3. Set them to some value (0,mean or median)  # housing[\"RM\"].fillna(housing[\"RM\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=imputer.transform(housing)\n",
    "housing_corrected=pd.DataFrame(X,columns=housing.columns)\n",
    "housing_corrected.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primarily this has three types of objects\n",
    "1. Estimators (imputer)\n",
    " - this has fit method (fits the data in the dataset and calculates internal parameters) & transform method.\n",
    "2. Transformers (takes input and returns output based on the learnings of the fit() this has a funtion fit_transform() )\n",
    "3. Predictors (LinearRegression model is an example of predictor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "my_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_pipe_corrected=my_pipeline.fit_transform(housing_corrected)\n",
    "housing_pipe_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
